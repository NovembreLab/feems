{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('feems': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b427e6b764d3ebce4814b0eea73cf2f68d5eddd2be147e79b42a1160529f9620"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Search for long range edges \n",
    "\n",
    "In this notebook, I will implement code to search for a long range edge(s) from a default `feems` by seeing if the likelihood increases with the addition of a certain edge. First, the search for the *best* edge will be done through a full grid search, wherein I iteratively add one long range edge after another over all pairs of nodes and check if this extra edge decreases the negative log likelihood. Second, I will implement a heuristic search by using a greedy approach to fit an edge between a pair of nodes that show maximum residuals with the default fit. \n",
    "\n",
    "To do this, I need to simulate a large empirical test case with many nodes. I will use the same corridor-barrier-corridor approach from previous simulations but with a much larger grid (40x80 is too large, for instance, 10x50 took 2 days to only get through ~1% of all edges). Keep total number of sampled nodes to about 40 maybe? \n",
    "\n",
    "## Changes to original code base\n",
    "\n",
    "1. added code to calculate the negative log likelihood value for fit in `spatial_graph.py` (basically, adding `Objective` functions)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# base\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pkg_resources\n",
    "import itertools as it\n",
    "import math\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import statsmodels.api as sm\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "# viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# feems\n",
    "from feems.utils import prepare_graph_inputs\n",
    "from feems import SpatialGraph, Viz, Objective\n",
    "from feems.sim import setup_graph, setup_graph_long_range, simulate_genotypes\n",
    "from feems.spatial_graph import query_node_attributes\n",
    "from feems.objective import comp_mats\n",
    "from feems.cross_validation import run_cv\n",
    "from feems.helper_funcs import plot_default_vs_long_range, comp_genetic_vs_fitted_distance, plot_estimated_vs_simulated_edges\n",
    "\n",
    "# change matplotlib fonts\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Arial\""
   ]
  },
  {
   "source": [
    "## Simulation test case\n",
    "\n",
    "### Exhaustive search \n",
    "\n",
    "This requires a search over a little less than $\\sim \\frac{d^2}{2}$ edges (for 128 nodes, it is about 7,800 edges). Using some kind of multithreading since this problem is embarassingly parellel. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simulating ~SNP 0\n",
      "Simulating ~SNP 50\n",
      "Simulating ~SNP 100\n",
      "Simulating ~SNP 150\n",
      "Simulating ~SNP 200\n",
      "Simulating ~SNP 250\n",
      "Simulating ~SNP 300\n",
      "Simulating ~SNP 350\n",
      "Simulating ~SNP 400\n",
      "Simulating ~SNP 450\n",
      "Simulating ~SNP 500\n",
      "Simulating ~SNP 550\n",
      "Simulating ~SNP 600\n",
      "Simulating ~SNP 650\n",
      "Simulating ~SNP 700\n",
      "Simulating ~SNP 750\n",
      "Simulating ~SNP 800\n",
      "Simulating ~SNP 850\n",
      "Simulating ~SNP 900\n",
      "Simulating ~SNP 950\n"
     ]
    }
   ],
   "source": [
    "n_rows, n_columns = 8, 16\n",
    "graph_def, _, _, edge_def = setup_graph(n_rows=n_rows, n_columns=n_columns, barrier_startpt=2.5, barrier_endpt=6.5, corridor_w=0.5, barrier_w=0.1, barrier_prob=1.0)\n",
    "\n",
    "lrn = [(0,38)]\n",
    "\n",
    "## using 1.0 to ensure all nodes are sampled equally well (default params otherwise: 4x8 grid)\n",
    "graph, coord, grid, edge = setup_graph_long_range(n_rows=n_rows, n_columns=n_columns, corridor_w=1.0, barrier_w=0.5, barrier_prob=1.0, long_range_nodes=lrn, long_range_edges=[1.5])\n",
    "\n",
    "gen_test = simulate_genotypes(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_Graph_def = SpatialGraph(gen_test, coord, grid, edge_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all edges to add (since it is symmetric, we should expect d(d-1)/2 but some will be adjacent nodes so fewer than that)\n",
    "lr = (tuple(i) for i in it.product(tuple(range(sp_Graph_def.n_observed_nodes)), repeat=2) if tuple(reversed(i)) > tuple(i))\n",
    "final_lr = [x for x in list(lr) if x not in list(sp_Graph_def.edges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index = np.arange(len(final_lr)), columns = ['nodes', 'nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes in an edge, adds to default graph and returns negative log-lik\n",
    "def add_edge(val):\n",
    "    edges_lr = deepcopy(edge_def)\n",
    "    edges_lr = edges_lr.tolist()\n",
    "    edges_lr.append(list(x+1 for x in val))\n",
    "    sp_Graph = SpatialGraph(gen_test, coord, grid, np.array(edges_lr))\n",
    "    sp_Graph.fit(lamb = 10.0, verbose=False)\n",
    "    obj = Objective(sp_Graph)\n",
    "    obj._solve_lap_sys()\n",
    "    obj._comp_mat_block_inv()\n",
    "    obj._comp_inv_cov()\n",
    "    return obj.neg_log_lik()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 7h 25min 18s, sys: 4min 15s, total: 7h 29min 34s\nWall time: 3h 39min 5s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 38)"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "%%time\n",
    "# for idx, val in enumerate(final_lr):\n",
    "#     # creating a new edge vector (all default edges + 1 long range)\n",
    "#     edges_lr = deepcopy(edge_def)\n",
    "#     edges_lr = edges_lr.tolist()\n",
    "#     edges_lr.append(list(x+1 for x in val))\n",
    "#     sp_Graph = SpatialGraph(gen_test, coord, grid, np.array(edges_lr))\n",
    "#     sp_Graph.fit(lamb = 10.0, verbose=False)\n",
    "\n",
    "#     df.iloc[idx, 0] = val\n",
    "#     df.iloc[idx, 1] = sp_Graph.nll\n",
    "\n",
    "# tbh no difference in timings between above for loop and one-liner map\n",
    "df['nodes'] = final_lr\n",
    "df['nll'] = list(map(add_edge, df.iloc[np.arange(len(final_lr)),0]))\n",
    "\n",
    "# print nodes connected by THE edge to give lowest negative log likelihood\n",
    "df.loc[df['nll'].astype(float).idxmin(),'nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 5min 33s, sys: 4.04 s, total: 5min 37s\nWall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # sequential run for timing purposes\n",
    "# df_test = pd.DataFrame(index = np.arange(100), columns = ['nodes', 'nll'])\n",
    "# for idx, val in enumerate(final_lr[0:100]):\n",
    "#     df_test.iloc[idx, 0] = val\n",
    "#     df_test.iloc[idx, 1] = add_edge(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       nodes           nll\n",
       "0     (0, 2)  13988.335454\n",
       "1     (0, 3)  13951.909591\n",
       "2     (0, 4)  13895.398119\n",
       "3     (0, 5)  13854.259583\n",
       "4     (0, 6)  13861.783873\n",
       "..       ...           ...\n",
       "95   (0, 98)  13950.784067\n",
       "96   (0, 99)  13976.136087\n",
       "97  (0, 100)   13929.84991\n",
       "98  (0, 101)  13870.904828\n",
       "99  (0, 102)   13878.63956\n",
       "\n",
       "[100 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nodes</th>\n      <th>nll</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(0, 2)</td>\n      <td>13988.335454</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(0, 3)</td>\n      <td>13951.909591</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(0, 4)</td>\n      <td>13895.398119</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(0, 5)</td>\n      <td>13854.259583</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(0, 6)</td>\n      <td>13861.783873</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>(0, 98)</td>\n      <td>13950.784067</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>(0, 99)</td>\n      <td>13976.136087</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>(0, 100)</td>\n      <td>13929.84991</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>(0, 101)</td>\n      <td>13870.904828</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>(0, 102)</td>\n      <td>13878.63956</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 5min 2s, sys: 30.9 s, total: 5min 33s\nWall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test['nodes'] = df.iloc[0:100,0]\n",
    "df_test['nll'] = list(map(add_edge, df_test.iloc[0:100,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/feems/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         '''\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/feems/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/feems/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/feems/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/feems/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# # this section of code takes forever, some overhead in communication potentially\n",
    "# pool = Pool(processes=mp.cpu_count())\n",
    "\n",
    "# nll = pool.map(add_edge, (val for val in df_test['nodes']))\n",
    "\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "\n",
    "# df_test['nll'] = nll"
   ]
  },
  {
   "source": [
    "Based on initial testing on the simulations, I find that an exhaustive search works well in recovering the long range edge based on maximum decrease in negative log-likelihood. \n",
    "\n",
    "### Implementing a heuristic seach\n",
    "\n",
    "We can use a data-driven apporach as before to find the pairs of nodes with highest residuals, and then search in a set region around the node. For instance, let's say, we get back (1,40) as the pair of nodes. We then implement a search in which we add edges between (0,40), (1,40), (2,40), ..., (2,41), etc. In this simple scheme, I will choose the six closest neighbors (forming a hexagon, if an interior node) to the selected nodes in the pair. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "constant-w/variance fit, converged in 123 iterations, train_loss=13990.5887471\nlambda=10.0000000, alpha=0.6633522, converged in 14 iterations, train_loss=12458.5572596\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-36b964c76e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmax_res_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_genetic_vs_fitted_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_Graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotFig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp_Graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_Graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_res_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# obtaining pairs of nodes with maximum residuals (TOP 1)\n",
    "max_res_nodes = comp_genetic_vs_fitted_distance(sp_Graph_def, n_lre=1, lamb=10.0, plotFig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting closest neighbors to each node with maximum residuals\n",
    "n1 = list(sp_Graph_def[max_res_nodes[0][0]])\n",
    "n2 = list(sp_Graph_def[max_res_nodes[0][1]])\n",
    "\n",
    "n1.append(max_res_nodes[0][0])\n",
    "n2.append(max_res_nodes[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_heur = (tuple(i) for i in it.product(n1, n2))\n",
    "# removing nodes that are already connected in the default graph \n",
    "final_lr_heur = [x for x in list(lr_heur) if x not in list(sp_Graph_def.edges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1min 2s, sys: 6.79 s, total: 1min 9s\nWall time: 35.5 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 38)"
      ]
     },
     "metadata": {},
     "execution_count": 310
    }
   ],
   "source": [
    "%%time\n",
    "df_heur = pd.DataFrame(index = np.arange(len(final_lr_heur)), columns = ['nodes', 'nll'])\n",
    "\n",
    "df_heur['nodes'] = final_lr_heur\n",
    "df_heur['nll'] = list(map(add_edge, df_heur.iloc[np.arange(len(final_lr_heur)),0]))\n",
    "\n",
    "# print nodes connected by THE edge to give lowest negative log likelihood\n",
    "df_heur.loc[df_heur['nll'].astype(float).idxmin(),'nodes']"
   ]
  },
  {
   "source": [
    "### Code to create an asymmetric convex hull around nodes\n",
    "\n",
    "Below I will write some code to create a search region around the selected nodes in which I will incorporate nodes to use in the search. Important use cases to keep in mind:  \n",
    "1. ensure that the two convex hulls are non-overlapping (i.e., at least 2 neighbors apart)  \n",
    "2. set a manual threshold if the closest sampled node is too far  \n",
    "\n",
    "#### Simulating an appropriate use-case\n",
    "\n",
    "This simulation will have unsampled nodes (sparse graph) in both the corridor and barrier regions. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_columns = 8, 12\n",
    "graph_def, coord_def, grid_def, edge_def = setup_graph(n_rows=n_rows, n_columns=n_columns, barrier_startpt=2.5, barrier_endpt=6.5, corridor_w=0.5, barrier_w=0.1, barrier_prob=1.0, sample_prob=0.5)\n",
    "\n",
    "# gen_test_def = simulate_genotypes(graph_def)\n",
    "\n",
    "# sp_Graph_def = SpatialGraph(gen_test_def, coord_def, grid_def, edge_def)\n",
    "\n",
    "# proj_test = ccrs.EquidistantConic(central_longitude=6.0, central_latitude=4.0)\n",
    "# # drawing the simulated graph \n",
    "# fig = plt.figure(dpi=100)\n",
    "# ax = fig.add_subplot(1, 1, 1)  \n",
    "# v = Viz(ax, sp_Graph_def, edge_width=.5, \n",
    "#         edge_alpha=1, edge_zorder=100, sample_pt_size=10, \n",
    "#         obs_node_size=7.5, sample_pt_color=\"black\", \n",
    "#         cbar_font_size=10)\n",
    "# v.draw_samples()\n",
    "# v.draw_edges(use_weights=False)\n",
    "# v.draw_obs_nodes(use_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[20  0  0  0 20  0  0  0 20  0  0 20]\n [ 0  0 20  0  0 20  0 20 20  0  0 20]\n [ 0 20  0  0 20  0  0  0 20 20  0 20]\n [20  0  0 20  0 20 20 20  0 20  0 20]\n [20  0  0 20 20  0 20 20  0 20 20 20]\n [ 0 20 20  0  0  0  0  0 20 20 20 20]\n [ 0 20 20  0 20  0  0  0 20 20  0 20]\n [ 0 20  0  0  0  0  0  0 20 20  0 20]]\n"
     ]
    }
   ],
   "source": [
    "# check nodes attributes and set long range nodes (0 is top-left)\n",
    "print(query_node_attributes(graph_def,\"sample_size\").reshape(n_rows,n_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Simulating ~SNP 0\n",
      "Simulating ~SNP 50\n",
      "Simulating ~SNP 100\n",
      "Simulating ~SNP 150\n",
      "Simulating ~SNP 200\n",
      "Simulating ~SNP 250\n",
      "Simulating ~SNP 300\n",
      "Simulating ~SNP 350\n",
      "Simulating ~SNP 400\n",
      "Simulating ~SNP 450\n",
      "Simulating ~SNP 500\n",
      "Simulating ~SNP 550\n",
      "Simulating ~SNP 600\n",
      "Simulating ~SNP 650\n",
      "Simulating ~SNP 700\n",
      "Simulating ~SNP 750\n",
      "Simulating ~SNP 800\n",
      "Simulating ~SNP 850\n",
      "Simulating ~SNP 900\n",
      "Simulating ~SNP 950\n"
     ]
    }
   ],
   "source": [
    "lrn = [(14,54)]\n",
    "\n",
    "graph, _, grid, edge = setup_graph_long_range(n_rows=n_rows, n_columns=n_columns, corridor_w=1.0, barrier_w=0.5, barrier_prob=1.0, long_range_nodes=lrn, long_range_edges=[1.5], sample_prob=1.0)\n",
    "\n",
    "# setting sample_size for nodes equal to the one from the default simulated graph\n",
    "for n in np.arange(len(graph_def.nodes)):\n",
    "    graph.nodes[n][\"sample_size\"] = graph_def.nodes[n][\"sample_size\"]\n",
    "\n",
    "gen_test = simulate_genotypes(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_Graph_def = SpatialGraph(gen_test, coord_def, grid_def, edge_def)\n",
    "\n",
    "# ensuring sample coords match the default graph created\n",
    "sample_sizes_dict = nx.get_node_attributes(graph_def, \"sample_size\")\n",
    "pops_def = [[i] * int(sample_sizes_dict[i] / 2) for i in graph_def.nodes]\n",
    "pops_def = list(it.chain.from_iterable(pops_def))\n",
    "coord = grid[pops_def,:]\n",
    "\n",
    "sp_Graph = SpatialGraph(gen_test, coord, grid, edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "constant-w/variance fit, converged in 128 iterations, train_loss=6184.4448289\nlambda=10.0000000, alpha=0.6500999, converged in 19 iterations, train_loss=5824.8858646\n"
     ]
    }
   ],
   "source": [
    "max_res_nodes = comp_genetic_vs_fitted_distance(sp_Graph_def, n_lre=1, lamb=10.0, plotFig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_idx = query_node_attributes(sp_Graph, \"permuted_idx\")\n",
    "max_idx = permuted_idx[np.unique(np.ravel(max_res_nodes))]\n",
    "max_res_nodes = list(zip(max_idx[::2],max_idx[1::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need some kind of distance measure to get sampled nodes closest to pair of \n",
    "spl = dict(nx.all_pairs_shortest_path_length(sp_Graph_def,cutoff=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get closest (within distance 3) AND sampled nodes to create a set of nodes to search over\n",
    "n1 = [k for (k, v) in spl[max_res_nodes[0][0]].items() if v>0 and v<3 and k in np.array(np.where(query_node_attributes(graph,\"sample_size\")>0))]\n",
    "n2 = [k for (k, v) in spl[max_res_nodes[0][1]].items() if v>0 and v<3 and k in np.array(np.where(query_node_attributes(graph,\"sample_size\")>0))]\n",
    "\n",
    "n1.append(max_res_nodes[0][0])\n",
    "n2.append(max_res_nodes[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_hull = (tuple(i) for i in it.product(n1, n2))\n",
    "# removing nodes that are already connected in the default graph \n",
    "final_lr_hull = [x for x in list(lr_hull) if x not in list(sp_Graph_def.edges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1min 8s, sys: 1.23 s, total: 1min 9s\nWall time: 30.5 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(14, 54)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "%%time\n",
    "df_hull = pd.DataFrame(index = np.arange(len(final_lr_hull)), columns = ['nodes', 'nll'])\n",
    "\n",
    "df_hull['nodes'] = final_lr_hull\n",
    "df_hull['nll'] = list(map(add_edge, df_hull.iloc[np.arange(len(final_lr_hull)),0]))\n",
    "\n",
    "# print nodes connected by THE edge to give lowest negative log likelihood\n",
    "df_hull.loc[df_hull['nll'].astype(float).idxmin(),'nodes']"
   ]
  },
  {
   "source": [
    "### Running an exact search "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all edges to add (since it is symmetric, we should expect d(d-1)/2 but some will be adjacent nodes so fewer than that)\n",
    "# but only between sampled nodes\n",
    "lr = (tuple(i) for i in it.product(tuple(permuted_idx), repeat=2) if tuple(reversed(i)) > tuple(i))\n",
    "final_lr = [x for x in list(lr) if x not in list(sp_Graph_def.edges)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 2h 52min 12s, sys: 3min, total: 2h 55min 12s\nWall time: 1h 16min 42s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(14, 54)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.DataFrame(index = np.arange(len(final_lr)), columns = ['nodes', 'nll'])\n",
    "\n",
    "df['nodes'] = final_lr\n",
    "df['nll'] = list(map(add_edge, df.iloc[np.arange(len(final_lr)),0]))\n",
    "\n",
    "# print nodes connected by THE edge to give lowest negative log likelihood\n",
    "df.loc[df['nll'].astype(float).idxmin(),'nodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " fold= 0\n",
      "iteration lambda=20/20 alpha=1/1\n",
      " fold= 1\n",
      "iteration lambda=20/20 alpha=1/1\n",
      " fold= 2\n",
      "iteration lambda=20/20 alpha=1/1\n",
      " fold= 3\n",
      "iteration lambda=20/20 alpha=1/1\n",
      " fold= 4\n",
      "iteration lambda=20/20 alpha=1/1"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[0.03047604],\n",
       "        [0.0304767 ],\n",
       "        [0.03047867],\n",
       "        [0.03047826],\n",
       "        [0.03040385],\n",
       "        [0.03038246],\n",
       "        [0.03029007],\n",
       "        [0.03026853],\n",
       "        [0.03016867],\n",
       "        [0.03017585],\n",
       "        [0.03010487],\n",
       "        [0.03002431],\n",
       "        [0.0299466 ],\n",
       "        [0.02988919],\n",
       "        [0.02986301],\n",
       "        [0.0298616 ],\n",
       "        [0.02987556],\n",
       "        [0.02989078],\n",
       "        [0.02989171],\n",
       "        [0.02988234]],\n",
       "\n",
       "       [[0.02956671],\n",
       "        [0.02956665],\n",
       "        [0.02951752],\n",
       "        [0.02951816],\n",
       "        [0.02945803],\n",
       "        [0.02945809],\n",
       "        [0.02938406],\n",
       "        [0.02932642],\n",
       "        [0.02928111],\n",
       "        [0.02924097],\n",
       "        [0.02916885],\n",
       "        [0.02909166],\n",
       "        [0.02901287],\n",
       "        [0.02895756],\n",
       "        [0.02892373],\n",
       "        [0.02890058],\n",
       "        [0.02888131],\n",
       "        [0.02886522],\n",
       "        [0.02885376],\n",
       "        [0.02884456]],\n",
       "\n",
       "       [[0.03175819],\n",
       "        [0.0317579 ],\n",
       "        [0.03175768],\n",
       "        [0.031614  ],\n",
       "        [0.03161379],\n",
       "        [0.03141102],\n",
       "        [0.03139744],\n",
       "        [0.0310689 ],\n",
       "        [0.0310172 ],\n",
       "        [0.03092183],\n",
       "        [0.030781  ],\n",
       "        [0.03072645],\n",
       "        [0.03069241],\n",
       "        [0.03065765],\n",
       "        [0.03063186],\n",
       "        [0.03061746],\n",
       "        [0.03061075],\n",
       "        [0.03060083],\n",
       "        [0.03058102],\n",
       "        [0.03055493]],\n",
       "\n",
       "       [[0.03247027],\n",
       "        [0.03247031],\n",
       "        [0.03249375],\n",
       "        [0.03249324],\n",
       "        [0.03242746],\n",
       "        [0.03242835],\n",
       "        [0.0321786 ],\n",
       "        [0.03198419],\n",
       "        [0.03198516],\n",
       "        [0.03187332],\n",
       "        [0.03176512],\n",
       "        [0.03160322],\n",
       "        [0.03142701],\n",
       "        [0.03121267],\n",
       "        [0.03106073],\n",
       "        [0.03097694],\n",
       "        [0.03093984],\n",
       "        [0.03092935],\n",
       "        [0.03093031],\n",
       "        [0.03093352]],\n",
       "\n",
       "       [[0.03209011],\n",
       "        [0.03208971],\n",
       "        [0.03213584],\n",
       "        [0.03213462],\n",
       "        [0.03211953],\n",
       "        [0.03209058],\n",
       "        [0.0320711 ],\n",
       "        [0.03154887],\n",
       "        [0.0310874 ],\n",
       "        [0.03076347],\n",
       "        [0.03051891],\n",
       "        [0.03037151],\n",
       "        [0.03033384],\n",
       "        [0.03032813],\n",
       "        [0.03032215],\n",
       "        [0.03031813],\n",
       "        [0.03031916],\n",
       "        [0.03031671],\n",
       "        [0.03030325],\n",
       "        [0.03028372]]])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "la = np.logspace(-6, 2, 20, dtype=\"float\")\n",
    "run_cv(sp_Graph_def, lamb_grid=la)\n",
    "# 'best' lambda was between 5 and 14 (so 10.0 is a pretty good approximation) "
   ]
  },
  {
   "source": [
    "## Jul 7, 2021\n",
    "\n",
    "### Methods\n",
    "\n",
    "I follow the same procedure as outlined in `sim-long-range.ipynb` to create a default, skeletal graph with no long range edges and then add an edge to this graph to simulate genotypes from. This procedure works with no extra frills for the case with complete sampling, i.e., each node sampled and all individuals sampled at each node.  \n",
    "However, for the case of incomplete sampling, the first step works as usual but the coordinates for the second graph needs to be adjusted based on the samples from the default graph. Another caveat is to look at the sampled nodes to see whether the long range nodes are actually being sampled (easy to check for small grid sizes, need an automated scheme for larger grids, but also takes much, much longer for exact solution)\n",
    "\n",
    "Then, I compute two solutions:  \n",
    "1. exact algorithm - add an edge between **all** pairs of nodes that are not already represented in default graph (slightly less than $\\frac{d^2}{2})  \n",
    "2. heuristic algorithm - only add edges between nodes that are located in the vicinity of the **one** pair of nodes with maximum residual (could be closest neighbors, could be an arbitrary convex hull to closest sampled nodes, etc.)\n",
    "\n",
    "### Main takeways\n",
    "\n",
    "It seems like both the exact search and heuristic search capture the long range edge easily, even in the case of uneven sampling. I will have to try more configurations/simulation parameters, but initial results are promising. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}